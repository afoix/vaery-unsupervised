    # Extract both embeddings and projections
#%%
import lightning as L
from typing import Callable
import numpy as np
import pytorch_lightning as pl
import torch
from iohub import open_ome_zarr
from iohub.ngff import Position
from monai.data import set_track_meta
from monai.transforms import Compose, ToTensord
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset
from monai.transforms import Compose, RandSpatialCrop, RandRotate, RandWeightedCrop, CenterSpatialCrop
import logging
from typing import Literal
import torch.nn.functional as F
from lightning import LightningModule
from monai.networks.nets.resnet import ResNetFeatures
from pytorch_metric_learning.losses import NTXentLoss, SelfSupervisedLoss
from torch import Tensor, nn
from typing_extensions import TypedDict

from vaery_unsupervised.dataloaders.hcs_dataloader_ryan import HCSDataModule
from vaery_unsupervised.networks.hcs_contrastive import ResNetEncoder, ContrastiveModule
from lightning.pytorch.loggers import TensorBoardLogger
from lightning.pytorch.callbacks import ModelCheckpoint
from pathlib import Path
import torchview
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
#%%
#Load data module
ome_zarr_path = "/mnt/efs/aimbl_2025/student_data/S-RM/full_dataset/RM_project_ome2.zarr"

data_module = HCSDataModule(
        ome_zarr_path=ome_zarr_path,
        source_channel_names=['mito','er','nuclei'],
        weight_channel_name='nuclei',
        crop_size=(128, 128),
        crops_per_position=4,
        batch_size=32,
        num_workers=6,
        split_ratio=0.8,
        normalization_transform=[],
        augmentations=[]
    )

data_module.setup(stage='val')
#%%

val_loader = data_module.val_dataloader()

#%%

ckpt_path = "/mnt/efs/aimbl_2025/student_data/S-RM/logs/contrastive_first/version_23/checkpoints/last.ckpt"

hcs_encoder_config = {
    "backbone": "resnet18",
    "in_channels": 3,
    "spatial_dims": 2,
    "embedding_dim": 512,
    "mlp_hidden_dims": 768,
    "projection_dim": 128,
    "pretrained": False,
}
hcs_encoder = ResNetEncoder(**hcs_encoder_config)

model = ContrastiveModule.load_from_checkpoint(
    ckpt_path,
    encoder=hcs_encoder,
    loss=SelfSupervisedLoss(NTXentLoss(temperature=0.07)),
    lr=1e-4,
)
model = model.cuda()
model.eval()

#%%
# all_emb, all_proj, all_pos_info = [], [], []
# with torch.no_grad():
#     for batch in val_loader:
#         emb, proj = model.encoder(batch["anchor"].cuda())
#         all_emb.append(emb.cpu())
#         all_proj.append(proj.cpu())
#         all_pos_info.extend(batch["position"])

# all_emb = torch.cat(all_emb, dim=0).numpy()
# all_proj = torch.cat(all_proj, dim=0).numpy()



all_emb, all_proj, all_pos_info = [], [], []

with torch.no_grad():
    for batch in val_loader:
        emb, proj = model.encoder(batch["anchor"].cuda())
        all_emb.append(emb.cpu())
        all_proj.append(proj.cpu())
        all_pos_info.extend(batch["pos_info"])  # <-- collect position info here

# concatenate tensors into numpy arrays
all_emb = torch.cat(all_emb, dim=0).numpy()
all_proj = torch.cat(all_proj, dim=0).numpy()
#%%
import pandas as pd

# Make DataFrame from all_proj
proj_df = pd.DataFrame(all_proj, columns=[f"proj_{i}" for i in range(all_proj.shape[1])])

# Make DataFrame for pos info
pos_df = pd.DataFrame(all_pos_info, columns=["pos_info"])
pos_df[["row", "col", "field"]] = pos_df["pos_info"].str.split("/", expand=True)

# Combine projections and position info into one table
full_df = pd.concat([proj_df, pos_df], axis=1)

# Optional: convert row/col/field to integers
full_df["row"] = full_df["row"].astype(int)
full_df["col"] = full_df["col"].astype(int)
full_df["field"] = full_df["field"].astype(int)

full_df.head()


#%%
annotations_path= '/mnt/efs/aimbl_2025/student_data/S-RM'

# Load annotation CSV
annotations = pd.read_csv(f"{annotations_path}/annotations.csv")
annotations = annotations.rename(columns={'row_num': 'row', 'column': 'col'})
#%%
# Ensure one row per well
annotations = annotations.drop_duplicates(subset=['row', 'col'])

# Merge 'gene' into full_df
full_df = full_df.merge(annotations['gene'], on=['row', 'col'], how='left')

# Check
print(full_df.head())
print(full_df.groupby(['row', 'col'])['gene'].nunique())  # should be 1 per well



#%%

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Reduce to 2D
pca = PCA(n_components=2)
proj_2d = pca.fit_transform(all_proj)

# Map positions to integer labels for coloring
unique_positions = list(set(all_positions))
pos_to_idx = {pos: i for i, pos in enumerate(unique_positions)}
colors = [pos_to_idx[p] for p in all_positions]

# Plot
plt.figure(figsize=(10, 8))
scatter = plt.scatter(proj_2d[:, 0], proj_2d[:, 1], 
                      c=colors, cmap="tab20", alpha=0.6)

# # Add legend with position IDs
# handles, _ = scatter.legend_elements(num=len(unique_positions))
# plt.legend(handles, unique_positions, title="Positions", bbox_to_anchor=(1.05, 1), loc="upper left")

plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("PCA of Contrastive Projections by Position")
plt.tight_layout()
plt.show()



# pca = PCA(n_components=2)
# proj_2d = pca.fit_transform(all_proj)

# plt.figure(figsize=(8,6))
# plt.scatter(proj_2d[:,0], proj_2d[:,1], alpha=0.5)
# plt.xlabel("PC1")
# plt.ylabel("PC2")
# plt.title("PCA of Contrastive Projections")
# plt.show()
#%%
import umap.umap_ as umap
import matplotlib.pyplot as plt

# Run UMAP on projections
umap_model = umap.UMAP(n_components=2, random_state=42)
proj_2d_umap = umap_model.fit_transform(all_proj)

# Map Position -> Well+Index label
pos_labels = []
for pos in all_positions:
    try:
        well = pos.parent  # should be the Well object
        label = f"{well.name}_P{pos.index}"  # e.g. A01_P0
    except AttributeError:
        label = str(pos)
    pos_labels.append(label)

# Assign colors
unique_labels = sorted(set(pos_labels))
label_to_idx = {lab: i for i, lab in enumerate(unique_labels)}
colors = [label_to_idx[lab] for lab in pos_labels]

# Plot UMAP scatter
plt.figure(figsize=(12, 10))
scatter = plt.scatter(proj_2d_umap[:, 0], proj_2d_umap[:, 1],
                      c=colors, cmap="tab20", alpha=0.6)

# # Legend
# handles, _ = scatter.legend_elements(num=len(unique_labels))
# plt.legend(handles, unique_labels, title="Well_Position",
#            bbox_to_anchor=(1.05, 1), loc="upper left", fontsize=8)

plt.xlabel("UMAP-1")
plt.ylabel("UMAP-2")
plt.title("UMAP of Contrastive Projections by Well and Position")
plt.tight_layout()
plt.show()




#%%
main()


#%%

import zarr
import json
from pathlib import Path

# Path to the dataset
zarr_path = Path("/mnt/efs/aimbl_2025/student_data/S-RM/full_dataset/RM_project_ome.zarr")

# open as a zarr group
root = zarr.open_group(str(zarr_path), mode="r")

# access attributes (.zattrs)
attrs = root.attrs.asdict()

# pretty print
print(json.dumps(attrs, indent=2))


 #%%





























